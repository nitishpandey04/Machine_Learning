{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_fit()_method_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "_y5CKZCgWMMd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvjxTYINOcmr",
        "outputId": "56316dd8-5ac2-4e46-ed12-00cf81b0b9c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U_z2V5GO4Rv",
        "outputId": "6e0312bf-784f-4d3b-9ba0-46bdc1ce208a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_images.reshape((train_images.shape[0], 28 * 28))\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "\n",
        "x_test = test_images.reshape((test_images.shape[0], 28 * 28))\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "y_train = train_labels.astype(\"float32\")\n",
        "y_test = test_labels.astype(\"float32\")"
      ],
      "metadata": {
        "id": "75nIQneAOtfE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "G0piiElQPWrA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fit() method implementation"
      ],
      "metadata": {
        "id": "PxCu4wspWLmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.RMSprop()\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
        "loss_metric = keras.metrics.Mean()\n",
        "\n",
        "def training_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(targets, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[metric.name] = metric.result()\n",
        "    loss_metric.update_state(loss)\n",
        "    logs[\"loss\"] = loss_metric.result()\n",
        "    return logs\n",
        "\n",
        "def reset_metrics():\n",
        "    for metric in metrics:\n",
        "        metric.reset_state()\n",
        "    loss_metric.reset_state()\n",
        "\n",
        "def fit(x_train, y_train, batch_size, epochs):\n",
        "    training_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    training_dataset = training_dataset.batch(batch_size)\n",
        "    for epoch in range(epochs):\n",
        "        reset_metrics()\n",
        "        for inputs_batch, labels_batch in training_dataset:\n",
        "            logs = training_step(inputs_batch, labels_batch)\n",
        "        print(f\"Epoch {epoch + 1} --> \", end=\"\")\n",
        "        for key, value in logs.items():\n",
        "            print(f\"{key} : {value:.4f}  \", end=\"\")\n",
        "        print(\"\")"
      ],
      "metadata": {
        "id": "TATf6Bl4WMJk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(model, x_train, y_train, 128, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyxebd14QQ3S",
        "outputId": "6a96d3a9-58ea-481d-8b2d-60f2af99fef6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 --> sparse_categorical_accuracy : 0.9038  loss : 0.3517  \n",
            "Epoch 2 --> sparse_categorical_accuracy : 0.9504  loss : 0.1755  \n",
            "Epoch 3 --> sparse_categorical_accuracy : 0.9645  loss : 0.1244  \n",
            "Epoch 4 --> sparse_categorical_accuracy : 0.9728  loss : 0.0957  \n",
            "Epoch 5 --> sparse_categorical_accuracy : 0.9779  loss : 0.0772  \n",
            "Epoch 6 --> sparse_categorical_accuracy : 0.9818  loss : 0.0640  \n",
            "Epoch 7 --> sparse_categorical_accuracy : 0.9851  loss : 0.0540  \n",
            "Epoch 8 --> sparse_categorical_accuracy : 0.9875  loss : 0.0463  \n",
            "Epoch 9 --> sparse_categorical_accuracy : 0.9896  loss : 0.0400  \n",
            "Epoch 10 --> sparse_categorical_accuracy : 0.9910  loss : 0.0348  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluate() method implementation"
      ],
      "metadata": {
        "id": "AR8fUcQkYxjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(inputs, targets):\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[\"val_\" + metric.name] = metric.result()\n",
        "        loss_metric.update_state(loss)\n",
        "        logs[\"val_loss\"] = loss_metric.result()\n",
        "        return logs\n",
        "\n",
        "def evaluate(x_test, y_test, batch_size):\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "    val_dataset = val_dataset.batch(batch_size)\n",
        "    reset_metrics()\n",
        "    for inputs_batch, targets_batch in val_dataset:\n",
        "        logs = test_step(inputs_batch, targets_batch)\n",
        "    print(\"Evaluation --> \", end=\"\")\n",
        "    for key, value in logs.items():\n",
        "        print(f\"{key} : {value:.4f}  \", end=\"\")\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "Ch9NnrKkWlRE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(x_test, y_test, 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIbqdZggWlNr",
        "outputId": "e0141057-28b8-4d0e-95f3-4f16df6c333f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation --> val_sparse_categorical_accuracy : 0.9736  val_loss : 0.0931  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X-_yqfDYWlLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RgxNU_HTWlIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w8BvadM_WlFu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}